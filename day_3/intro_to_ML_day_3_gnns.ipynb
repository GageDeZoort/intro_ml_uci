{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_k2_1jVg7se"
      },
      "source": [
        "# UCI Introduction to Machine Learning\n",
        "**Day 3: Graph Neural Networks**\n",
        "\n",
        "\n",
        "Notebook adapted by Gage DeZoort from a similar notebook offered in his tutorial, [Graph Neural Networks for your Research](https://github.com/GageDeZoort/prc_gnn_tutorial/blob/main/gnn_tutorial.ipynb).\n",
        "\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/GageDeZoort/intro_ml_uci/blob/main/day_2/intro_to_ML_day_3_gnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCxSzBlAO8Qc"
      },
      "source": [
        "# 0. Software Installation\n",
        "Just click through the following cells, no need to linger!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dPZoTN-O8Qh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# check the torch/cuda installations\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWKTgiKgPWHz"
      },
      "source": [
        "Given the current PyTorch/Cuda installations, we'll install [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e347zJLlPWH0"
      },
      "outputs": [],
      "source": [
        "# install PyTorch Geometric (PyG)\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyTorch Geometric (PyG)** is a high-level library for **graph deep learning** built on PyTorch.  \n",
        "It provides data structures, layers, and utilities to build **GNNs** (Graph Neural Networks) for tasks like node/edge/graph classification, link prediction, and graph regression—at scale."
      ],
      "metadata": {
        "id": "kmTgnG3gB-Wx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7L06AMTPkXG"
      },
      "source": [
        "# 1. Graph-Structured Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/GageDeZoort/intro_ml_uci/main/day_3/images/graph.png\" width=\"500\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "dTYkgLGIADb9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zFhyCyViG7K"
      },
      "source": [
        "A **graph** $G$ is a mathematical object consisting of a set of **nodes** (vertices) $V$ and their pairwise relationships encoded as **edges** $E$, i.e. $G=(V,E)$. In the following we will usually denote $|V|=n_\\mathrm{nodes}$ and $|E|=n_\\mathrm{edges}$.\n",
        "\n",
        "Graphs can easily represent a wide range of structured data including **atoms in molecules** (nodes=atoms, edges=molecular bonds), **users in a social network** (nodes=people, edges=social connections), **cities and roads in a transportation system** (nodes=cities, edges=roads), **planetary simulations** (nodes=planets, edges=gravitational interactions), and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvFu7PH-QhUQ"
      },
      "source": [
        "In PyG, graphs are stored as `Data` objects (see the [docs](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data)). Given a graph named `data`, we will find in many cases that it has several of the following attributes:\n",
        "\n",
        "- `data.x`: node feature matrix of dimension $n_\\mathrm{nodes}\\times d_V$, where $d_V$ is the number of features attached to each node.\n",
        "- `data.edge_index`: a sparse edge list in COO format indicating node indices at each end of each edge; this object has size $2\\times n_\\mathrm{edges}$.\n",
        "- `data.edge_attr`: edge feature matrix of dimension $n_\\mathrm{edges}\\times d_E$, where $d_E$ is the number of features attached to each edges.\n",
        "- `data.y`: training target with arbitary shape (remember, targets may be node-level, edge-level, or graph-level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncrmLPJTTHzt"
      },
      "source": [
        "##  1.1 Karate Club\n",
        "Let's take a look at an example graph in PyG. The Zachary Karate Club dataset (1977) is a social network describing friendships in a university karate club:\n",
        "- 34 nodes (members of the karate club)\n",
        "- 78 edges (friendships outside of the club)\n",
        "\n",
        "A conflict arose between an instructor and an adminstrator, causing a faction in the club - half of the members formed a new karate club around the previous instructor and half either found a new instructor or quit karate.\n",
        "- Truth labels: faction, 0 or 1 (per node)\n",
        "\n",
        "Note that this is a single graph, and the goal is to perform *node classification* on the training set of nodes (a subset of all the nodes in the graph). In this way, Karate Club is used for semi-supervised node classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmtNysTPDItb"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import KarateClub\n",
        "\n",
        "# KarateClub is a small, easily visualized community graph\n",
        "karate_club = KarateClub()._data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avnsgyVzTT8s"
      },
      "source": [
        "> **Exercise 1.1a**: In the following cell, print the KarateClub object and its attributes, `x`, `edge_index`, `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t55h9g5gTOW-"
      },
      "outputs": [],
      "source": [
        "# EXERCISE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxHytqWMUWae"
      },
      "source": [
        "As a brief aside, let's take a look at how PyG stores edges. In a fully connected graph, there are $\\frac{1}{2}n_\\mathrm{nodes}(n_\\mathrm{nodes}-1)$ edges. Sparse graphs have relatively few edges, i.e. $n_\\mathrm{edges}\\ll \\frac{1}{2}n_\\mathrm{nodes}(n_\\mathrm{nodes}-1)$. Adjacency matrices aren't necessarily the best way to represent sparse graphs - instead, packages like PyG use edge index lists in COO format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7YKvbviUgAI"
      },
      "outputs": [],
      "source": [
        "# edge lists (COO format)\n",
        "out_nodes = karate_club.edge_index[0]\n",
        "print('edges move out of the following nodes:\\n', out_nodes)\n",
        "in_nodes = karate_club.edge_index[1]\n",
        "print('edges move into the following nodes:\\n', in_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS6OH8PWYeZo"
      },
      "source": [
        "**Exercise 1.1b** Use `torch_geometric.utils.to_dense_adj` to generate an adjacency matrix from `edge_index`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjuvIuyvZDTJ"
      },
      "outputs": [],
      "source": [
        "# EXERCISE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QavjEjaZFUi"
      },
      "source": [
        "We can print several additional details about the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFopSRjNDTVR"
      },
      "outputs": [],
      "source": [
        "# more details about the graph\n",
        "def get_graph_stats(data):\n",
        "  print(f'Number of nodes: {data.num_nodes}')\n",
        "  print(f'Number of edges: {data.num_edges}')\n",
        "  print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "  print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "  print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "  print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "  print(f'Has self-loops: {data.has_self_loops()}')\n",
        "  print(f'Is undirected: {data.is_undirected()}')\n",
        "\n",
        "get_graph_stats(karate_club)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neRlpItMTyb2"
      },
      "source": [
        "Okay, good, we've taken a look at our first instance of `Data`. Now let's visualize the graph; note that here it has 4 truth labels instead of 2, which have been generated by a graph clustering algorithm (if you're interested see [this ref](https://ieeexplore.ieee.org/document/4358966), but it's not important here). We'll use `networkx`, a networks dynamics software package, to visualize the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pU3DOgPD9TP"
      },
      "outputs": [],
      "source": [
        "import torch_geometric\n",
        "import networkx as networkx\n",
        "print('Truth labels', karate_club.y)\n",
        "karate_club_nx = torch_geometric.utils.to_networkx(karate_club, to_undirected=True)\n",
        "plt.figure(figsize=(10,10))\n",
        "nx.draw(karate_club_nx, with_labels=True, node_color=karate_club.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCJ2dJ3QXA66"
      },
      "source": [
        "## 1.2 ENZYMES Graphs\n",
        "\n",
        "Karate Club is used for semi-supervised node classification; let's look at a dataset used for graph-level classification. The [ENZYMES dataset](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.TUDataset.html#torch_geometric.datasets.TUDataset)\n",
        "contains 600 graphs representing proteins with ~32.6 nodes (secondary structure elements - helices, turns or sheets) and ~124.3 edges (denoting neighbors in space or in the amino acid sequence) each. For expert details see the [TUDataset paper](https://arxiv.org/pdf/2007.08663.pdf). The goal is to assign each protein to one of 6 enzyme commission numbers, which describe the chemical reaction the enzyme catalyzes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN6PiQJMW_tM"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "dataset = TUDataset(root='/tmp/TUDataset', name=\"ENZYMES\", use_node_attr=True)\n",
        "dataset.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdlJ3pY0c-Gt"
      },
      "source": [
        "For PyG `datasets` containing multiple graphs, you'll typically want to use a `DataLoader` to load up batches of graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sf5FRdvdMND"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "for batch in loader:\n",
        "  print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FPIlskdrtM"
      },
      "source": [
        "**Exercise 1.1c**: Notice also that the data batches appear to have concatenate the nodes and edges of all the graphs into a single \"batch graph.\" How does this work? (Hint: look at the `batch` attribute appended to each batch.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN67VQlVe1Q-"
      },
      "outputs": [],
      "source": [
        "# EXERCISE\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhbB7-VLdiaK"
      },
      "source": [
        "# 2. Graph Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHFDitSOstcp"
      },
      "source": [
        "In general, GNNs work by leveraging **local information** across the graph structure to intelligently compute new features for the nodes (and/or edges). A commonly used class of GNNs is the **Graph Convolutional Network (GCN)**. GCNs use more-or-less the same convolution operations you've seen used in CNNs; however, instead of applying them to patches of images, they apply them to node neighborhoods.\n",
        "\n",
        "**Message** are computed from each of a node's neighbors, and these messages are passed back to the node and used to update its features. We're going to make this painfully concrete; first, here's a schematic:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1f5MJO9Kw1tWjJMBJBsZ-M4tMFz_dydr2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0Njbs0chR5O"
      },
      "source": [
        "## 2.1 Graph Convolutional NNs\n",
        "\n",
        "Let’s look at the **Graph Convolutional Network (GCN)** as introduced in  \n",
        "[Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/pdf/1609.02907.pdf).  \n",
        "Don’t worry if the details look dense — we’ll highlight the main intuition.\n",
        "\n",
        "The layer update rule is:\n",
        "\n",
        "$$\n",
        "\\mathbf{x}_u^{(\\ell + 1)} =\n",
        "\\sum_{v \\in N(u) \\cup \\{v\\}}\n",
        "\\frac{1}{c_{uv}} \\, \\mathbf{x}_v^{(\\ell)} \\mathbf{W}^{(\\ell + 1)}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔍 What this means\n",
        "- In the $\\ell^\\mathrm{th}$ GNN layer, each node $v$ updates its representation $\\mathbf{x}_v^{(\\ell+1)}$ by aggregating the feature vectors of its **neighbors** (and itself).  \n",
        "- $\\mathbf{W}^{(\\ell+1)}$ a matrix of learnable weights shared across all nodes in layer $\\ell+1$.  \n",
        "- $c_{uv}$ is a **normalization factor** ensuring that high-degree nodes don’t dominate the aggregation.  \n",
        "  In the original GCN paper:\n",
        "  $$\n",
        "  c_{uv} = \\sqrt{(deg(u)+1)(deg(v)+1)}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧩 Intuition\n",
        "You can think of this operation as a **weighted average of the neighborhood features**:\n",
        "- Each node “looks” at its neighbors,\n",
        "- Scales their features by a normalization term,\n",
        "- And mixes them through a shared linear transformation.\n",
        "\n",
        "In matrix form, this corresponds to multiplying the node feature matrix $\\mathbf{X}\\in\\mathbb{R}^{|V|\\times N}$\n",
        "by a normalized adjacency matrix $\\tilde{\\mathbf{A}}$ — a diffusion-like smoothing that blends information locally across the graph.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCKmtkS8kl3d"
      },
      "source": [
        "## 2.2 Cora (Karate Club but bigger!)\n",
        "\n",
        "We will now use the [Cora dataset](https://relational.fit.cvut.cz/dataset/CORA) to predict the subject of a research paper given its words and citation network. The learning task is the same as it was with Karate Club, **semi-supervised node classification**. The Cora dataset consists of\n",
        "\n",
        "- 2,708 nodes (scientific papers)\n",
        "- 7 truth classes (paper subjects)\n",
        "- 5,429 edges (representing citations)\n",
        "- 1,433 node features (each a binary field indicating the presence of a word in the corresponding paper)\n",
        "\n",
        "Let's go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUq4BYlX_5Nd"
      },
      "outputs": [],
      "source": [
        "# import the cora citation network\n",
        "from torch_geometric.datasets import Planetoid\n",
        "cora_dataset = Planetoid(root='data/Planetoid', name='Cora')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47atFcJGBTNV"
      },
      "outputs": [],
      "source": [
        "# there is only one graph in this dataset\n",
        "cora = cora_dataset[0]\n",
        "cora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QtrGNbXn1Nm"
      },
      "source": [
        "**Exercise 2.2a** Print out the train, val, and test masks. How many nodes are we training with? How could this affect the prediction task?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5V7xVGtoAUT"
      },
      "outputs": [],
      "source": [
        "# EXERCISE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTW3g1qTCWMQ"
      },
      "outputs": [],
      "source": [
        "# use our previous function to inspect Cora\n",
        "get_graph_stats(cora)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYmgukT-PUmG"
      },
      "outputs": [],
      "source": [
        "# let's visualize the graph\n",
        "plt.figure(figsize=(10,10))\n",
        "cora_nx = torch_geometric.utils.to_networkx(cora, to_undirected=True)\n",
        "nx.draw(cora_nx, node_size=15, node_color=cora.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Tx630GBNQe"
      },
      "source": [
        "Okay, now it's time to set up a GCN using PyG! Reminder: we can construct a GNN in PyG similary to how we build a standard feed-forward neural network. We just need to swap the `torch.nn.Linear` layers with PyG's `GCNConv` implementing the graph convolution:\n",
        "\n",
        "$$\n",
        "\\mathbf{x}_u^{(\\ell + 1)} =\n",
        "\\sum_{v \\in N(u) \\cup \\{v\\}}\n",
        "\\frac{1}{c_{uv}} \\, \\mathbf{x}_v^{(\\ell)} \\mathbf{W}^{(\\ell + 1)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPOvTx-fCwPD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(cora_dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, cora_dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index) # apply first GCN convolution\n",
        "        x = F.relu(x) # hidden graph embedding\n",
        "        x = F.dropout(x, training=self.training) # randomly drop training nodes\n",
        "        x = self.conv2(x, edge_index) # output graph embedding\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHzB82jBj2v"
      },
      "source": [
        "This GCN is very similar to the [original implementation](https://github.com/tkipf/pygcn).\n",
        "\n",
        "Let's take a look at the predictions of an untrained GCN by looking at a low dimensional representation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYpVv-myJ1Cz"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "# examine the output of an untrained GCN\n",
        "model = GCN()\n",
        "model.eval()\n",
        "out = model(cora)\n",
        "visualize(out, color=cora.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRwpfp2JpNPE"
      },
      "source": [
        "As an aside, we've used another dimensionality reduction technique called **t-SNE (t-Distributed Stochastic Neighbor Embedding)**. It creates a low-dimensional map that preserves *local relationships* in high-dimensional data, making clusters and structure visually interpretable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is as good a time as any to introduce the **Adam** optimizer.  \n",
        "\n",
        "**Adam (Adaptive Moment Estimation)** is one of the most widely used optimization algorithms in deep learning.  \n",
        "It combines the strengths of **Momentum** and **RMSProp** to adapt the learning rate for each parameter individually.\n",
        "\n",
        "Each parameter is updated as:\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\frac{\\widehat{m}_t}{\\sqrt{\\widehat{v}_t} + \\epsilon}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "- **Momentum ($m_t$)** → smooths updates by tracking an exponential moving average of past gradients  \n",
        "- **Adaptive scaling ($v_t$)** → adjusts each parameter’s step size based on its gradient variance  \n",
        "- Works reliably *out of the box*, especially in settings with noisy or sparse gradients.\n"
      ],
      "metadata": {
        "id": "DQO3R_ICF3Cv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11WFfacNbBat"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = GCN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(data):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data)  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "def test(data):\n",
        "      model.eval()\n",
        "      out = model(data)\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
        "      return test_acc\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train(cora)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wxqSUPcbNfU"
      },
      "outputs": [],
      "source": [
        "test_acc = test(cora)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qhFhde5CSgD"
      },
      "source": [
        "Not perfect, but it's pretty accurate at predicting paper subject area!\n",
        "\n",
        "We can further verify that  by looking at the output embeddings of our **trained** model, which now produces a far better clustering of nodes of the same category.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDrdFWyscGQu"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "out = model(cora)\n",
        "visualize(out, color=cora.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egGOxxmkunCJ"
      },
      "source": [
        "**Exercise 2.2b** Play around with the training loop above! Some guiding questions:\n",
        "\n",
        "- How does GCN behave when increasing the hidden feature dimensionality or the number of layers? Does increasing the number of layers help at all?\n",
        "\n",
        "- So far, we've just looked at GCNConv operations. You can try to use different GNN layers to see how model performance changes. What happens if you swap out all GCNConv instances with GATConv layers that make use of attention? Try to write a 2-layer GAT model that makes use of 8 attention heads in the first layer and 1 attention head in the second layer, uses a dropout ratio of 0.6 inside and outside each GATConv call, and uses a hidden_channels dimensions of 8 per head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urJuiyo7wCBc"
      },
      "outputs": [],
      "source": [
        "# EXERCISE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29h_pmkkwDnf"
      },
      "outputs": [],
      "source": [
        "# EXERCISE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoBSUkB3wC8q"
      },
      "outputs": [],
      "source": [
        "# EXERCISE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solutions to Exercises"
      ],
      "metadata": {
        "id": "Ej0tUCW4Fumq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quOauueqYuIZ"
      },
      "outputs": [],
      "source": [
        "# answers to exercises:\n",
        "\n",
        "# Exercise 1.1a\n",
        "# print(karate_club.x)\n",
        "# print(karate_club.edge_index)\n",
        "# print(karate_club.y)\n",
        "\n",
        "# Exercise 1.1b\n",
        "# A = torch_geometric.utils.to_dense_adj(karate_club.edge_index).squeeze()\n",
        "#print('adjacency representation', A)\n",
        "\n",
        "# Exercise 1.1c\n",
        "# Batching in PyG works by concatenating nodes and creating a block diagonal adacency matrix.\n",
        "# Membership is tracked through the `batch` attribute appended to each graph batch.\n",
        "# See: https://pytorch-geometric.readthedocs.io/en/latest/advanced/batching.html\n",
        "\n",
        "# Exercise 2.2a\n",
        "# sum(cora.train_mask)\n",
        "# There are 140 training nodes, 20 from each of the 7 truth classes.\n",
        "# This means overtraining is a real possibility and regularization will be important.\n",
        "\n",
        "# Exercise 2.2b\n",
        "# Adding more layers doesn't help too much (and even hurts if the network becomes too deep)!\n",
        "# This is because node features get \"washed out\" across the graph.\n",
        "\n",
        "# Exercise 3a\n",
        "# 21 input features, 6 output classes\n",
        "# x = global_mean_pool(x, data.batch)\n",
        "\n",
        "# Exercise 3b\n",
        "# Just copy the train loop structure and the accuracy metric from the Cora train loop.\n",
        "# But remember accuracy is computed per-graph now!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "iCxSzBlAO8Qc",
        "z7L06AMTPkXG",
        "dhbB7-VLdiaK",
        "Ej0tUCW4Fumq"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}